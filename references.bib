@techreport{Pan,
abstract = {The Census Bureau developed guidelines for the translation of data collection instruments and supporting materials in order to ensure that such documents translated from a source language into a target language are reliable, complete, accurate, and culturally appropriate. In addition to meeting these criteria, guidelines were developed to ensure that translated Census Bureau data collection instruments also have semantic, conceptual, and normative equivalence. The guideline recommends that the translation of data collection instruments from a source language into a target language be conducted using a translation team. The guideline relies on the cross-cultural and survey methodology research literature and specifies and describes five steps that comprise the translation process. These steps are: Prepare, Translate, Pretest, Revise, and Document.},
address = {Washington D.C.},
author = {Pan, Yuling and de la Puente, Manuel},
booktitle = {Research Report Series},
file = {:C\:/Users/andre/Documents/Mendeley Desktop/Pan, de la Puente - 2005 - Census Bureau guideline for the translation of data collection instruments and supporting materials documenta.pdf:pdf},
institution = {Statistical Research Division, U.S. Bureau of the Census},
keywords = {cross-cultural issues in survey design,data quality,non-English speaking populations,survey translation},
pages = {1--38},
title = {{Census Bureau guideline for the translation of data collection instruments and supporting materials: documentation on how the guideline was developed}},
url = {https://www.census.gov/srd/papers/pdf/rsm2005-06.pdf},
volume = {6},
year = {2005}
}
@article{Seo2014,
abstract = {Purpose: To examine the influence of translation when measuring and comparing self-rated health (SRH) measured with five response categories (excellent, very good, good, fair, and poor), across racial/ethnic groups. Methods: Using data from the California Health Interview Survey, which were administered in five languages, we analyzed variations in the five-category SRH across five racial/ethnic groups: non-Hispanic white, Latino, Chinese, Vietnamese, and Korean. Logistic regression was used to estimate independent effects of race/ethnicity, culture, and translation on SRH, after controlling for risk factors and other measures of health status. Results: Latinos, Chinese, Vietnamese, and Koreans were less likely than non-Hispanic whites to rate their health as excellent or very good and more likely to rate it as good, fair, or poor. This racial/ethnic difference diminished when adjusting for acculturation. Independently of race/ethnicity, respondents using non-English surveys were less likely to answer excellent (OR = 0.24-0.55) and very good (OR = 0.30-0.34) and were more likely to answer fair (OR = 2.48-4.10) or poor (OR = 2.87-3.51), even after controlling for other measures of SRH. Conclusions: Responses to the five-category SRH question depend on interview language. When responding in Spanish, Chinese, Korean, or Vietnamese, respondents are more likely to choose a lower level SRH category, "fair" in particular. If each SRH category measured in different languages is treated as equivalent, racial/ethnic disparities in SRH among Latinos and Asian subgroups, as compared to non-Hispanic whites, may be exaggerated. {\textcopyright} 2013 Springer Science+Business Media Dordrecht.},
author = {Seo, Sukyong and Chung, Sukyung and Shumway, Martha},
doi = {10.1007/s11136-013-0522-6},
issn = {09629343},
journal = {Quality of Life Research},
keywords = {Ethnicity,Public health,Self-rated health,Translation},
month = {mar},
number = {2},
pages = {593--600},
pmid = {24026633},
publisher = {Springer},
title = {{How good is "very good"? Translation effect in the racial/ethnic variation in self-rated health status}},
url = {https://link.springer.com/article/10.1007/s11136-013-0522-6},
volume = {23},
year = {2014}
}
@article{Biemer2010,
abstract = {The total survey error (TSE) paradigm provides a theoretical framework for optimizing surveys by maximizing data quality within budgetary constraints. In this article, the TSE paradigm is viewed as part of a much larger design strategy that seeks to optimize surveys by maximizing total survey quality; i.e., quality more broadly defined to include user-specified dimensions of quality. Survey methodology, viewed within this larger framework, alters our perspectives on the survey design, implementation, and evaluation. As an example, although a major objective of survey design is to maximize accuracy subject to costs and timeliness constraints, the survey budget must also accommodate additional objectives related to relevance, accessibility, interpretability, comparability, coherence, and completeness that are critical to a survey's "fitness for use." The article considers how the total survey quality approach can be extended beyond survey design to include survey implementation and evaluation. In doing so, the "fitness for use" perspective is shown to influence decisions regarding how to reduce survey error during design implementation and what sources of error should be evaluated in order to assess the survey quality today and to prepare for the surveys of the future. {\textcopyright} The Author 2011.},
author = {Biemer, Paul P.},
doi = {10.1093/POQ/NFQ058},
file = {:C\:/Users/andre/Documents/Mendeley Desktop/Biemer - 2010 - Total Survey Error Design, Implementation, and Evaluation.pdf:pdf},
issn = {0033-362X},
journal = {Public Opinion Quarterly},
month = {jan},
number = {5},
pages = {817--848},
publisher = {Oxford Academic},
title = {{Total Survey Error: Design, Implementation, and Evaluation}},
url = {https://academic.oup.com/poq/article/74/5/817/1815551},
volume = {74},
year = {2010}
}
@article{Hicks2010,
abstract = {Computer audio-recorded interviewing (CARI) has been used for more than a decade to detect field-interview fabrication, but it has the potential for much more. On the 2007 National Home and Hospice Care Survey, an innovative CARI system combined with behavior coding assessed problematic questions, monitored general compliance with protocols, and evaluated individual interviewer performance. This article discusses the benefits of CARI for recording large samples of interviews in a systematic, objective manner at reduced cost and less operational burden than traditional audio recording. The increased objectivity and volume of recordings allowed identification of potential data-quality issues, specifically measurement error due to the questionnaire, the interviewer, and their interaction. CARI's potential as a tool for estimating the magnitude of the error in survey data is also discussed. {\textcopyright} The Author 2011.},
author = {Hicks, W. D. and Edwards, B. and Tourangeau, K. and McBride, B. and Harris-Kojetin, L. D. and Moss, A. J.},
doi = {10.1093/poq/nfq063},
file = {:C\:/Users/andre/Documents/Mendeley Desktop/Hicks et al. - 2010 - Using Cari Tools To Understand Measurement Error.pdf:pdf},
issn = {0033-362X},
journal = {Public Opinion Quarterly},
month = {jan},
number = {5},
pages = {985--1003},
publisher = {Oxford Academic},
title = {{Using Cari Tools To Understand Measurement Error}},
url = {https://academic.oup.com/poq/article-lookup/doi/10.1093/poq/nfq063},
volume = {74},
year = {2010}
}
@book{EuropeanSocialSurvey2018,
abstract = {Abgerufen: 03.08.2020, 19:25},
address = {London},
author = {{European Social Survey}},
file = {:C\:/Users/andre/Documents/Mendeley Desktop/European Social Survey - 2018 - ESS Round 9 Translation Guidelines.pdf:pdf},
publisher = {ESS ERIC Headquarters},
title = {{ESS Round 9 Translation Guidelines}},
url = {https://www.europeansocialsurvey.org/docs/round9/methods/ESS9_translation_guidelines.pdf},
year = {2018}
}
